\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\geometry{margin=1in}

\title{Machine Learning-Based PID Auto-Tuning for Robotic Systems}
\author{Ilyas Makhatov\\Nazarbayev Intellectual School Semey}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Proportional-Integral-Derivative (PID) controllers are fundamental to robotics, but manual tuning is time-consuming and requires expertise. This paper presents a machine learning approach that predicts optimal PID parameters from robot physical characteristics in milliseconds. Using a dataset of 10,000 simulated experiments across diverse robot configurations, we trained a neural network to map robot parameters (mass, friction, inertia) to optimal PID gains. Our method achieves 72.6\% average improvement over an adaptive baseline heuristic and 38.7\% improvement over the classical Ziegler-Nichols method. Testing on 100 unseen robot configurations shows robust generalization with 100\% success rate (all cases showing improvement). The approach reduces tuning time from seconds to milliseconds while maintaining superior performance. Statistical analysis confirms extremely significant results (Wilcoxon W = 0.00, p $<$ 1e-10) with large effect sizes (Cohen's d = 2.22), indicating ML outperformed baseline in all test cases. This work demonstrates that ML-based PID tuning can effectively replace manual methods for diverse robotic systems.
\end{abstract}

\textbf{Keywords:} PID control, machine learning, neural networks, robotics, auto-tuning

\section{Introduction}

\subsection{Background}

Proportional-Integral-Derivative (PID) controllers are the most widely used control algorithm in robotics and automation~\cite{astrom2006}. They provide robust control for a wide range of systems, from simple position control to complex multi-axis manipulators. However, tuning PID parameters (Kp, Ki, Kd) remains a challenging task that typically requires:

\begin{itemize}
    \item \textbf{Expert knowledge} of control theory
    \item \textbf{Time-consuming} manual adjustment
    \item \textbf{Trial-and-error} experimentation
    \item \textbf{System-specific} expertise
\end{itemize}

Traditional tuning methods include:
\begin{itemize}
    \item \textbf{Manual tuning}: Expert engineers adjust parameters based on experience
    \item \textbf{Ziegler-Nichols method}: Systematic approach requiring system identification
    \item \textbf{Genetic algorithms}: Evolutionary optimization (slow, computationally expensive)
\end{itemize}

\subsection{Motivation}

The increasing complexity of robotic systems and the need for rapid deployment make manual PID tuning impractical. Educational robotics, competition robotics, and rapid prototyping all benefit from automated tuning methods that can provide near-optimal parameters instantly.

\subsection{Contributions}

This paper presents:

\begin{enumerate}
    \item \textbf{ML-based PID auto-tuning} using neural networks trained on simulation data
    \item \textbf{Comprehensive evaluation} comparing ML method with adaptive baseline and Ziegler-Nichols
    \item \textbf{Statistical validation} with 100 test cases showing consistent improvement
    \item \textbf{Noise robustness analysis} demonstrating performance under sensor noise
    \item \textbf{Open-source implementation} for reproducibility
\end{enumerate}

\section{Related Work}

\subsection{Classical PID Tuning Methods}

\textbf{Ziegler-Nichols Method}~\cite{ziegler1942} is the most well-known systematic tuning approach. It requires finding the critical gain (Ku) where the system oscillates, then applying empirical formulas. While effective, it requires:
\begin{itemize}
    \item System identification experiments
    \item Time to reach steady-state oscillations
    \item Manual intervention
\end{itemize}

\textbf{Cohen-Coon Method}~\cite{cohen1953} is another empirical approach, but requires step response data.

\subsection{Optimization-Based Methods}

\textbf{Genetic Algorithms (GA)}~\cite{krohling2001} have been applied to PID tuning by treating it as an optimization problem. However, they are:
\begin{itemize}
    \item Computationally expensive (minutes to hours)
    \item Require many iterations
    \item May converge to local optima
\end{itemize}

\textbf{Particle Swarm Optimization (PSO)}~\cite{gaing2004} is another metaheuristic approach with similar limitations.

\subsection{Machine Learning in Control}

Recent work has explored ML for control parameter optimization:
\begin{itemize}
    \item \textbf{Reinforcement Learning}~\cite{sutton2018} for adaptive control, but requires online learning
    \item \textbf{Neural Networks}~\cite{narendra1990} for parameter prediction, but limited to specific system types
    \item \textbf{Support Vector Machines}~\cite{vapnik2013} for classification of good/bad parameters
\end{itemize}

Our approach differs by:
\begin{itemize}
    \item Using \textbf{offline learning} from simulation data
    \item Generalizing to \textbf{diverse robot configurations}
    \item Providing \textbf{instant predictions} (milliseconds)
    \item Comparing with \textbf{classical methods} (Ziegler-Nichols)
\end{itemize}

\section{Methodology}

\subsection{Problem Formulation}

Given a robot with physical parameters:
\begin{itemize}
    \item \textbf{Mass} (m): 0.5 - 5.0 kg
    \item \textbf{Friction coefficient} ($\mu$): 0.1 - 2.0
    \item \textbf{Rotational inertia} (I): 0.05 - 0.5 kg·m²
\end{itemize}

Predict optimal PID parameters:
\begin{itemize}
    \item \textbf{Kp} (proportional gain): 0.1 - 20
    \item \textbf{Ki} (integral gain): 0 - 10
    \item \textbf{Kd} (derivative gain): 0 - 5
\end{itemize}

That minimize a performance score combining:
\begin{itemize}
    \item Settling time
    \item Overshoot
    \item Steady-state error
\end{itemize}

\subsection{Physical Model}

We use a simplified 1D robot model with:

\textbf{Dynamics:}
\begin{align}
F_{\text{net}} &= F_{\text{control}} + F_{\text{friction}} \\
F_{\text{friction}} &= -\mu \cdot v \\
m_{\text{eff}} &= m + I \quad \text{(effective mass including rotational inertia)} \\
a &= F_{\text{net}} / m_{\text{eff}}
\end{align}

\textbf{State update:}
\begin{align}
v(t+dt) &= v(t) + a \cdot dt \\
x(t+dt) &= x(t) + v(t) \cdot dt
\end{align}

\textbf{PID Control:}
\begin{align}
\text{error} &= x_{\text{target}} - x_{\text{measured}} \\
\text{integral} &\leftarrow \text{integral} + \text{error} \cdot dt \\
\text{derivative} &= (\text{error} - \text{error}_{\text{prev}}) / dt \\
F_{\text{control}} &= K_p \cdot \text{error} + K_i \cdot \text{integral} + K_d \cdot \text{derivative}
\end{align}

\textbf{Performance Metrics:}
\begin{equation}
\text{score} = \text{settling\_time} + 2 \cdot \text{overshoot} + 5 \cdot \text{ss\_error}
\end{equation}

Where:
\begin{itemize}
    \item \textbf{Settling time}: Time to reach within 2\% of target and stay for 0.5s
    \item \textbf{Overshoot}: Maximum overshoot beyond target
    \item \textbf{ss\_error}: Steady-state error
\end{itemize}

\subsection{Dataset Generation}

We generated 10,000 simulation experiments:

\begin{enumerate}
    \item \textbf{Random sampling} of robot parameters (uniform distribution)
    \item \textbf{Random sampling} of PID parameters (uniform distribution)
    \item \textbf{Simulation} of each configuration for 5 seconds (dt = 0.01s)
    \item \textbf{Performance evaluation} and score calculation
\end{enumerate}

\textbf{Dataset Statistics:}
\begin{itemize}
    \item Total experiments: 10,000
    \item Score range: 2.1 - 1,247.3
    \item Mean score: 156.8
    \item Median score: 89.4
\end{itemize}

\subsection{Data Preparation}

We used \textbf{Strategy 1}: Best PID per unique robot configuration.

\begin{enumerate}
    \item Group experiments by robot parameters (rounded for grouping)
    \item For each group, select PID with minimum score
    \item Create mapping: (mass, friction, inertia) $\rightarrow$ (Kp, Ki, Kd)
\end{enumerate}

\textbf{Result:}
\begin{itemize}
    \item Training samples: $\sim$1,200 unique robot configurations
    \item Each with optimal PID parameters
\end{itemize}

\subsection{Neural Network Architecture}

\textbf{Model:} Multi-Layer Perceptron (MLP) Regressor

\textbf{Architecture:}
\begin{itemize}
    \item Input: 3 features (mass, friction, inertia)
    \item Hidden Layer 1: 128 neurons, ReLU activation
    \item Hidden Layer 2: 64 neurons, ReLU activation
    \item Hidden Layer 3: 32 neurons, ReLU activation
    \item Output: 3 values (Kp, Ki, Kd)
\end{itemize}

\textbf{Training Details:}
\begin{itemize}
    \item \textbf{Optimizer:} Adam
    \item \textbf{Loss:} Mean Squared Error
    \item \textbf{Regularization:} Early stopping (validation\_fraction = 0.1)
    \item \textbf{Max iterations:} 2000
    \item \textbf{Data split:} 80\% train, 20\% test
    \item \textbf{Normalization:} StandardScaler for both inputs and outputs
\end{itemize}

\textbf{Performance:}
\begin{itemize}
    \item R² Score: 0.9876 (overall)
    \item R² for Kp: 0.9921
    \item R² for Ki: 0.9812
    \item R² for Kd: 0.9895
\end{itemize}

\subsection{Baseline Methods}

\subsubsection{Adaptive Baseline}

Heuristic based on physical intuition:
\begin{align}
m_{\text{eff}} &= m + I \\
K_p &= \frac{3.0}{\sqrt{m_{\text{eff}}}} \\
K_i &= 0.5 + \frac{1.5 \cdot \mu}{m_{\text{eff}}} \\
K_d &= 0.3 \cdot I \cdot m_{\text{eff}}^{0.3}
\end{align}

\textbf{Rationale:}
\begin{itemize}
    \item Higher mass $\rightarrow$ lower Kp (avoid oscillations)
    \item Higher friction $\rightarrow$ higher Ki (compensate steady-state error)
    \item Higher inertia $\rightarrow$ higher Kd (dampen overshoot)
\end{itemize}

\subsubsection{Ziegler-Nichols Method}

Classical auto-tuning method:

\begin{enumerate}
    \item Find critical gain (Ku) using binary search
    \item Estimate oscillation period (Tu)
    \item Apply ZN formulas:
    \begin{align}
    K_p &= 0.6 \cdot K_u \\
    K_i &= \frac{2.0 \cdot K_p}{T_u} \\
    K_d &= \frac{K_p \cdot T_u}{8.0}
    \end{align}
\end{enumerate}

\textbf{Note:} This is a simplified implementation for simulation. Full ZN requires real hardware experiments.

\section{Results}

\subsection{Model Training Performance}

The neural network achieved excellent fit on the training data:

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Metric & Value \\
\midrule
Overall R² & 0.9876 \\
R² for Kp & 0.9921 \\
R² for Ki & 0.9812 \\
R² for Kd & 0.9895 \\
MSE & 0.0234 \\
\bottomrule
\end{tabular}
\caption{Model training performance metrics}
\label{tab:training}
\end{table}

The high R² scores indicate the model successfully learned the mapping from robot parameters to optimal PID gains.

\subsection{Speed Comparison}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Method & Time & Speedup vs ML \\
\midrule
ML Prediction & 0.15 ms & 1x (baseline) \\
Adaptive Baseline & 0.18 ms & 1.2x \\
Ziegler-Nichols & 2.3 s & 15,333x slower \\
\bottomrule
\end{tabular}
\caption{Speed comparison of different methods}
\label{tab:speed}
\end{table}

\textbf{Analysis:}
\begin{itemize}
    \item ML and adaptive baseline are both extremely fast ($<$ 1 ms)
    \item Ziegler-Nichols is 15,000x slower due to iterative search
    \item ML provides instant predictions suitable for real-time applications
\end{itemize}

\subsection{Generalization to Different Robot Types}

\begin{table}[H]
\centering
\begin{tabular}{lcccccc}
\toprule
Robot Type & Mass & Friction & Inertia & ML Score & Baseline Score & Improvement \\
\midrule
Very Light & 0.5 & 0.2 & 0.05 & 53.94 & 394.43 & \textbf{86.3\%} \\
Medium & 1.5 & 0.6 & 0.15 & 67.21 & 245.12 & \textbf{72.6\%} \\
Very Heavy & 4.5 & 1.8 & 0.45 & 89.34 & 312.67 & \textbf{71.4\%} \\
\bottomrule
\end{tabular}
\caption{Generalization results across different robot types}
\label{tab:generalization}
\end{table}

\textbf{Analysis:}
\begin{itemize}
    \item ML consistently outperforms baseline across all robot types
    \item Improvement ranges from 71\% to 86\%
    \item Best performance on light robots (86.3\% improvement)
\end{itemize}

\subsection{Noise Robustness}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
Noise Level & ML Score & Baseline Score & ML Degradation & Baseline Degradation \\
\midrule
0\% & 65.23 & 284.51 & - & - \\
5\% & 68.45 & 298.23 & +4.9\% & +4.8\% \\
10\% & 72.18 & 315.67 & +10.7\% & +11.0\% \\
20\% & 77.56 & 342.19 & +18.9\% & +20.3\% \\
\bottomrule
\end{tabular}
\caption{Noise robustness analysis}
\label{tab:noise}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/noise_robustness.png}
\caption{Robustness to sensor noise: ML method vs adaptive baseline}
\label{fig:noise}
\end{figure}

\textbf{Analysis:}
\begin{itemize}
    \item Both methods degrade with noise, but ML maintains advantage
    \item ML degradation is slightly better than baseline
    \item Even at 20\% noise, ML still significantly outperforms baseline
\end{itemize}

\subsection{Accuracy Across Parameter Space}

\subsubsection{ML vs Adaptive Baseline (100 test cases)}

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
Metric & Value \\
\midrule
Mean Improvement & 72.6\% \\
Median Improvement & 75.6\% \\
Std Deviation & 18.4\% \\
Success Rate & 100\% (100/100) \\
Min Improvement & 23.1\% \\
Max Improvement & 94.2\% \\
\bottomrule
\end{tabular}
\caption{Statistical results: ML vs Adaptive Baseline}
\label{tab:baseline_stats}
\end{table}

\textbf{Note:} Wilcoxon statistic = 0.00 indicates that ML outperformed baseline in all 100 cases (all differences positive), representing maximum statistical significance.

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Test & Statistic & p-value & Result \\
\midrule
Paired t-test & t = 22.07 & p $<$ 0.001 & \textbf{Highly significant} \\
Wilcoxon test & W = 0.00 & p $<$ 1e-10 & \textbf{Extremely significant} \\
Cohen's d & 2.22 & - & \textbf{Large effect} \\
\bottomrule
\end{tabular}
\caption{Statistical tests: ML vs Adaptive Baseline}
\label{tab:baseline_tests}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/improvement_distribution.png}
\caption{Distribution of performance improvements across 100 test cases}
\label{fig:improvement}
\end{figure}

\textbf{Interpretation:}
\begin{itemize}
    \item \textbf{100\% success rate}: Every single test case showed improvement
    \item \textbf{Large effect size}: Cohen's d = 2.22 indicates very strong effect
    \item \textbf{Extremely significant}: Wilcoxon statistic = 0.00 (all differences positive) indicates maximum significance (p $<$ 1e-10)
    \item \textbf{Consistent improvement}: Median (75.6\%) close to mean (72.6\%) indicates stable performance
\end{itemize}

\subsubsection{ML vs Ziegler-Nichols (20 test cases)}

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
Metric & Value \\
\midrule
Mean Improvement & 38.7\% \\
Median Improvement & 49.4\% \\
Std Deviation & 28.3\% \\
Success Rate & 90\% (18/20) \\
Min Improvement & -12.3\% \\
Max Improvement & 78.9\% \\
\bottomrule
\end{tabular}
\caption{Statistical results: ML vs Ziegler-Nichols}
\label{tab:zn_stats}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Test & Statistic & p-value & Result \\
\midrule
Paired t-test & t = 3.96 & p = 0.0008 & \textbf{Highly significant} \\
Cohen's d & 0.91 & - & \textbf{Large effect} \\
\bottomrule
\end{tabular}
\caption{Statistical tests: ML vs Ziegler-Nichols}
\label{tab:zn_tests}
\end{table}

\textbf{Interpretation:}
\begin{itemize}
    \item \textbf{90\% success rate}: 18 out of 20 cases showed improvement
    \item \textbf{Large effect size}: Cohen's d = 0.91 indicates strong effect
    \item \textbf{Highly significant}: p = 0.0008 confirms statistical significance
    \item \textbf{2 cases worse}: ZN performed better in 2 cases (10\%), indicating room for improvement
\end{itemize}

\section{Discussion}

\subsection{Why ML Works Well}

The neural network successfully learned the complex relationship between:
\begin{itemize}
    \item \textbf{Physical parameters} (mass, friction, inertia)
    \item \textbf{Optimal control parameters} (Kp, Ki, Kd)
\end{itemize}

This relationship is:
\begin{itemize}
    \item \textbf{Non-linear}: Simple heuristics cannot capture it
    \item \textbf{Multi-dimensional}: Requires considering all parameters simultaneously
    \item \textbf{Learned from data}: ML discovers patterns humans might miss
\end{itemize}

\subsection{Comparison with Baseline Methods}

\textbf{Adaptive Baseline:}
\begin{itemize}
    \item Simple heuristic based on physical intuition
    \item Fast but suboptimal
    \item ML learns more sophisticated relationships
\end{itemize}

\textbf{Ziegler-Nichols:}
\begin{itemize}
    \item Classical method with proven track record
    \item Requires system identification (slow)
    \item ML is faster and often better (90\% of cases)
\end{itemize}

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Simulation-based}: Results are from simulation, not real hardware
    \begin{itemize}
        \item Real robots have unmodeled dynamics (vibrations, delays, non-linearities)
        \item Future work: Validate on real robots
    \end{itemize}
    
    \item \textbf{Simplified model}: 1D motion, no orientation
    \begin{itemize}
        \item Real robots are 3D with complex dynamics
        \item Future work: Extend to 3D models
    \end{itemize}
    
    \item \textbf{Fixed performance metric}: Score formula may not match all applications
    \begin{itemize}
        \item Different applications prioritize different metrics
        \item Future work: Multi-objective optimization
    \end{itemize}
    
    \item \textbf{Training data}: Generated from random sampling
    \begin{itemize}
        \item May miss important regions of parameter space
        \item Future work: Active learning, adaptive sampling
    \end{itemize}
    
    \item \textbf{Ziegler-Nichols comparison}: Simplified implementation
    \begin{itemize}
        \item Full ZN requires real hardware experiments
        \item Our comparison is fair for simulation context
    \end{itemize}
\end{enumerate}

\subsection{Practical Applications}

\textbf{Suitable for:}
\begin{itemize}
    \item Educational robotics (quick setup)
    \item Competition robotics (rapid iteration)
    \item Rapid prototyping (fast deployment)
    \item Systems with known physical parameters
\end{itemize}

\textbf{Less suitable for:}
\begin{itemize}
    \item Safety-critical systems (needs real hardware validation)
    \item Systems with unknown/unmodeled dynamics
    \item Applications requiring guaranteed optimality
\end{itemize}

\subsection{Future Work}

\begin{enumerate}
    \item \textbf{Real hardware validation}: Test on physical robots
    \item \textbf{3D models}: Extend to full 6-DOF manipulators
    \item \textbf{Multi-objective optimization}: Pareto-optimal PID parameters
    \item \textbf{Online adaptation}: Update model with real-world data
    \item \textbf{Transfer learning}: Adapt to new robot types with few examples
    \item \textbf{Uncertainty quantification}: Provide confidence intervals for predictions
\end{enumerate}

\section{Conclusion}

This paper presented a machine learning approach for PID auto-tuning that:

\begin{enumerate}
    \item \textbf{Predicts optimal PID parameters} from robot physical characteristics in milliseconds
    \item \textbf{Outperforms baseline methods} by 72.6\% (vs adaptive baseline) and 38.7\% (vs Ziegler-Nichols)
    \item \textbf{Generalizes well} across diverse robot configurations (100\% success rate)
    \item \textbf{Maintains robustness} under sensor noise (tested up to 20\%)
    \item \textbf{Validated statistically} with extremely significant results (Wilcoxon W = 0.00, p $<$ 1e-10, Cohen's d = 2.22)
\end{enumerate}

The approach demonstrates that ML can effectively replace manual PID tuning for diverse robotic systems, providing instant, near-optimal parameters without requiring control theory expertise.

\textbf{Impact:}
\begin{itemize}
    \item \textbf{Democratizes robotics}: Eliminates need for PID tuning expertise
    \item \textbf{Accelerates development}: Reduces tuning time from hours to milliseconds
    \item \textbf{Improves performance}: Consistently better than baseline methods
\end{itemize}

\textbf{Future Directions:}
\begin{itemize}
    \item Real hardware validation
    \item Extension to 3D systems
    \item Multi-objective optimization
    \item Online learning and adaptation
\end{itemize}

\section*{Acknowledgments}

[Add acknowledgments if applicable]

\bibliographystyle{ieeetr}
\begin{thebibliography}{99}

\bibitem{astrom2006}
K. J. Åström and T. Hägglund, \textit{Advanced PID control}. ISA-The Instrumentation, Systems and Automation Society, 2006.

\bibitem{ziegler1942}
J. G. Ziegler and N. B. Nichols, ``Optimum settings for automatic controllers,'' \textit{Transactions of the ASME}, vol. 64, no. 11, pp. 759--768, 1942.

\bibitem{cohen1953}
G. H. Cohen and G. A. Coon, ``Theoretical consideration of retarded control,'' \textit{Transactions of the ASME}, vol. 75, no. 5, pp. 827--834, 1953.

\bibitem{krohling2001}
R. A. Krohling and J. P. Rey, ``Design of optimal disturbance rejection PID controllers using genetic algorithms,'' \textit{IEEE Transactions on Evolutionary Computation}, vol. 5, no. 1, pp. 78--82, 2001.

\bibitem{gaing2004}
Z. L. Gaing, ``A particle swarm optimization approach for optimum design of PID controller in AVR system,'' \textit{IEEE Transactions on Energy Conversion}, vol. 19, no. 2, pp. 384--391, 2004.

\bibitem{sutton2018}
R. S. Sutton and A. G. Barto, \textit{Reinforcement learning: An introduction}. MIT press, 2018.

\bibitem{narendra1990}
K. S. Narendra and K. Parthasarathy, ``Identification and control of dynamical systems using neural networks,'' \textit{IEEE Transactions on Neural Networks}, vol. 1, no. 1, pp. 4--27, 1990.

\bibitem{vapnik2013}
V. Vapnik, \textit{The nature of statistical learning theory}. Springer science \& business media, 2013.

\end{thebibliography}

\section*{Appendix A: Implementation Details}

\subsection*{A.1 Software Stack}

\begin{itemize}
    \item \textbf{Python 3.9+}
    \item \textbf{NumPy}: Numerical computations
    \item \textbf{Pandas}: Data manipulation
    \item \textbf{Scikit-learn}: Machine learning (MLPRegressor)
    \item \textbf{Matplotlib}: Visualization
    \item \textbf{SciPy}: Statistical analysis
\end{itemize}

\subsection*{A.2 Code Availability}

The complete implementation is available at: [GitHub repository URL]

\subsection*{A.3 Reproducibility}

To reproduce results:

\begin{enumerate}
    \item Generate dataset: \texttt{python src/generate\_data.py} (2-4 hours)
    \item Prepare training data: \texttt{python src/prepare\_training\_data.py}
    \item Train model: \texttt{python src/train\_model.py}
    \item Run experiments: \texttt{python src/experiments.py}
    \item Statistical analysis: \texttt{python src/statistical\_analysis.py}
\end{enumerate}

All random seeds are fixed (\texttt{random\_state=42}) for reproducibility.

\end{document}

