# Project Architecture: ML-Based PID Parameter Optimization for Robots

## Overview

This project uses machine learning to predict optimal PID (Proportional-Integral-Derivative) controller parameters based on robot physical characteristics. The system trains a neural network on data generated by physical simulation.

## Modules

### 1. `robot_simulator_corrected.py` - Physical Simulation (Corrected)
**Purpose**: Modeling robot physics with dimensionally correct dynamics and testing PID controller.

**Components**:
- `RobotSimulator` - robot physical model class
  - Parameters: mass (kg), damping_coeff (N·s/m), inertia (kg·m²), radius (m, fixed 0.1)
  - Effective mass: `m_eff = m + I/r²` (dimensionally correct)
  - State: position (m), velocity (m/s), target position (1.0 m)
  - Actuator limits: ±50 N
  - Method `step()`: one simulation step using F=ma law
  
- `test_pid_with_antiwindup()` - Advanced PID controller testing function
  - Input: robot, PID parameters (Kp, Ki, Kd), optional anti-windup and derivative filtering
  - Output: performance metrics
    - `settling_time`: settling time (within 2% of target)
    - `overshoot`: maximum overshoot (%)
    - `ss_error`: steady-state error (m)
    - `itae`: Integral of Time-weighted Absolute Error
    - `iae`: Integral of Absolute Error
    - `ise`: Integral of Squared Error

**Physical Model**:
- Damping force: `-damping_coeff * velocity` (N)
- Net force: `control_force + damping_force`
- Acceleration: `a = F_net / m_eff` (m/s²)
- Integration: Euler method with dt=0.01 s
- Target: 1.0 m (realistic 1 meter)

### 2. `generate_data_optimized.py` - Dataset Generation (Optimization-Based)
**Purpose**: Creating high-quality training dataset using Nelder-Mead optimization.

**Process**:
1. Generates 1,000 unique robot configurations
2. For each robot:
   - Random robot parameters: mass ∈ [0.5, 5.0], damping_coeff ∈ [0.1, 2.0], inertia ∈ [0.05, 0.5]
   - Uses Nelder-Mead optimization to find optimal PID parameters (minimize ITAE)
   - Bounds: Kp ∈ [0.1, 100], Ki ∈ [0, 50], Kd ∈ [0, 20]
   - Max 500 iterations, 2-5 seconds per robot
3. Saves results to `pid_dataset.csv`

**Output**:
- CSV file with columns: mass, damping_coeff, inertia, Kp, Ki, Kd, settling_time, overshoot, ss_error, itae, iae, ise, optimization_time

### 3. `data_preparation.py` - Common Data Preparation Module
**Purpose**: Centralized logic for data preparation, eliminating code duplication (DRY principle).

**Components**:
- `load_dataset()`: load dataset from CSV
- `save_training_data()`: save prepared data
- `print_statistics()`: print data statistics
- `strategy_best_per_robot()`: best PID for each unique robot configuration
- `prepare_features_labels()`: extract features and labels

**Principle**: Single point for common logic, strategies extracted into separate functions.

### 4. `prepare_training_data.py` - Data Preparation
**Purpose**: Select best PID parameters for each unique robot.

**Strategy**:
1. Uses `strategy_best_per_robot()` from `data_preparation.py`
2. Groups data by robot parameters (with rounding for grouping)
3. For each group, finds PID with minimum score
4. Creates pairs (robot parameters → optimal PID parameters)

**Output**:
- `X_train.npy`: robot parameters (mass, damping_coeff, inertia)
- `y_train.npy`: optimal PID parameters (Kp, Ki, Kd)

### 5. `train_model.py` - Model Training
**Purpose**: Train neural network to predict PID parameters.

**Model Architecture**:
- Type: MLPRegressor (multi-layer perceptron)
- Architecture: 3 → 128 → 64 → 32 → 3
- Activation: ReLU
- Optimizer: Adam
- Regularization: Early stopping with validation_fraction=0.1

**Process**:
1. Load data (X_train.npy, y_train.npy)
2. Split train/test (80/20)
3. Normalize data (StandardScaler for X and y)
4. Train model
5. Evaluate quality (R², MSE for each parameter)
6. Save model and scalers

**Output Files**:
- `pid_model.pkl`: trained model
- `scaler_X.pkl`: input data scaler
- `scaler_y.pkl`: output data scaler

### 6. `predict_pid.py` - PID Parameter Prediction
**Purpose**: Use trained model to predict optimal PID parameters.

**Functions**:
- `predict_pid(mass, damping_coeff, inertia)`: main prediction function
  - Loads model and scalers
  - Normalizes input data
  - Makes prediction
  - Denormalizes output data
  - Returns dictionary with Kp, Ki, Kd

**Modes**:
- Interactive: prompts user for parameters
- Command line: accepts parameters as arguments

**Input**: robot parameters (mass, damping_coeff in N·s/m, inertia in kg·m²)  
**Output**: predicted PID parameters (Kp, Ki, Kd)

### 7. `test_model.py` - Model Testing
**Purpose**: Test trained model on new robots and compare with baseline manual tuning.

**Functions**:
- `load_model()`: load model and scalers
- `predict_pid()`: predict PID parameters
- `main()`: main testing loop

**Process**:
1. Tests on 3 robot types (light, medium, heavy)
2. Compares ML predictions with Adaptive Baseline, Cohen-Coon, and CHR methods
3. Calculates performance improvement (ITAE-based)
4. Creates comparison plots with all methods

**Output Files**:
- `results_comparison.png`: ML vs Baseline/CC/CHR comparison plots for each robot type

### 8. `experiments.py` - Experiments for Research Paper
**Purpose**: Conduct experiments to validate method and prepare data for paper.

**Experiments**:
1. **Speed comparison**: ML prediction vs Baseline/CC/CHR (10,000 iterations for precision)
2. **Generalization**: Testing on different robot types (very light, medium, very heavy)
3. **Noise robustness**: Performance at various sensor noise levels (0%, 5%, 10%, 20%)
4. **Accuracy across parameter space**: Testing on 1,000 random robots

**Output Files**:
- `noise_robustness.png`: noise robustness plot
- `improvement_distribution.png`: performance improvement distribution (ML vs all baselines)
- `experiment_results.npy`: results for statistical analysis

### 9. `statistical_analysis_improved.py` - Comprehensive Statistical Analysis
**Purpose**: Comprehensive statistical analysis of experiment results for research paper.

**Analysis Methods**:
- **Paired t-test**: compare ML and baseline methods
- **Wilcoxon signed-rank test**: non-parametric alternative
- **Sign test**: most robust test
- **Multiple effect sizes**: Cohen's d, Hedge's g, Glass's delta, Cliff's delta
- **Bootstrap confidence intervals**: 95% CI for mean/median improvement
- **Normality tests**: Shapiro-Wilk test
- **Descriptive statistics**: means, medians, standard deviations, IQR

**Output Files**:
- `statistical_comparison_baseline.png`: comprehensive plots ML vs Baseline
- `statistical_comparison_cc.png`: comprehensive plots ML vs Cohen-Coon
- `statistical_comparison_chr.png`: comprehensive plots ML vs CHR
- `statistical_results_improved.json`: all statistical metrics
- LaTeX tables for paper (printed to console)

## Data Flows

### Data Generation
```
generate_data_optimized.py (Nelder-Mead optimization) → pid_dataset.csv
```

### Data Preparation
```
pid_dataset.csv → prepare_training_data.py → X_train.npy, y_train.npy
```

### Training
```
X_train.npy, y_train.npy → train_model.py → pid_model.pkl, scaler_X.pkl, scaler_y.pkl
```

### Usage
```
robot_params → predict_pid.py → predicted_PID_params
```

Details:
```
robot_params (mass, damping_coeff, inertia) → scaler_X → model → scaler_y → predicted_PID_params (Kp, Ki, Kd)
```

### Testing and Experiments
```
pid_model.pkl → test_model.py → results_comparison.png
pid_model.pkl → experiments.py → experiment_results.npy
experiment_results.npy → statistical_analysis_improved.py → statistical_comparison_*.png + statistical_results_improved.json
```

## Data Schemas

### Input Data (X)
- `mass`: robot mass [0.5, 5.0] kg
- `damping_coeff`: viscous damping coefficient [0.1, 2.0] N·s/m
- `inertia`: moment of inertia [0.05, 0.5] kg·m²
- `radius`: characteristic radius (fixed 0.1 m)

### Output Data (y)
- `Kp`: proportional coefficient [0.1, 100]
- `Ki`: integral coefficient [0, 50]
- `Kd`: derivative coefficient [0, 20]

### Performance Metrics
- `settling_time`: settling time (seconds, within 2% of target)
- `overshoot`: maximum overshoot (%)
- `ss_error`: steady-state error (m)
- `itae`: Integral of Time-weighted Absolute Error (primary metric)
- `iae`: Integral of Absolute Error
- `ise`: Integral of Squared Error

## Dependencies

- `numpy`: numerical computations
- `pandas`: data manipulation
- `matplotlib`: visualization
- `tqdm`: progress bar
- `scikit-learn`: machine learning
- `joblib`: model saving
- `scipy`: statistical analysis

## Non-Functional Requirements

- **Performance**: Dataset generation takes 1-2 hours (1,000 robots, Nelder-Mead optimization)
- **Accuracy**: Model evaluated by R² and MSE for each PID parameter. Current R² = 0.0873 (overall), but provides substantial practical improvements (78-90% vs baselines)
- **Scalability**: Architecture allows easy increase of dataset size or optimization iterations

## Architectural Decisions

1. **Separation of simulation and training**: Physical model separated from ML components
2. **Centralization of data preparation logic**: `data_preparation.py` module eliminates duplication (DRY)
3. **Data normalization**: StandardScaler for training stability
4. **Early stopping**: Prevents overfitting
5. **Modularity**: Each component has clear responsibility (SOLID)

## Architecture Changelog

### 2025-01-XX (Major Corrections and Improvements)
- **Created `robot_simulator_corrected.py`**: Fixed dimensional inconsistency (m_eff = m + I/r²)
- **Created `generate_data_optimized.py`**: Replaced random search with Nelder-Mead optimization
- **Created `statistical_analysis_improved.py`**: Comprehensive statistical analysis with bootstrap CI, multiple effect sizes
- **Added baseline methods**: Cohen-Coon and CHR for comprehensive comparison
- **Updated experiments**: 1,000 test cases, all baseline methods included
- **Reason**: Address reviewer concerns about physics, data quality, and statistical rigor
- **Impact**: Dimensionally correct model, higher-quality training data, comprehensive statistical validation

### 2025-01-XX (Experiments and Analysis)
- **Added experiment modules**: `test_model.py`, `experiments.py`, `statistical_analysis_improved.py`
- **Implemented 4 experiments**: speed comparison, generalization, noise robustness, accuracy (1,000 cases)
- **Added comprehensive statistical analysis**: paired t-test, Wilcoxon test, Sign test, multiple effect sizes, bootstrap CI
- **Reason**: Prepare data for research paper, validate method
- **Impact**: Full cycle from training to statistical validation ready for publication

### 2025-01-XX (Refactoring)
- **Created `data_preparation.py` module**: Centralized data preparation logic
- **Added `predict_pid.py` module**: Tool for using trained model
- **Reason**: Follow DRY and SOLID principles, improve code maintainability
- **Impact**: Single entry point for predictions, cleaner code structure

### 2025-01-XX (Base Version)
- **Created base architecture**: Modules for simulation, data generation, data preparation, and training
- **Data preparation strategy**: Best PID per unique robot configuration
- **Reason**: Research approach to training data preparation
- **Impact**: Clean mapping from robot parameters to optimal PID parameters
