# Project Architecture: ML-Based PID Parameter Optimization for Robots

## Overview

This project uses machine learning to predict optimal PID (Proportional-Integral-Derivative) controller parameters based on robot physical characteristics. The system trains a neural network on data generated by physical simulation.

## Modules

### 1. `robot_simulator.py` - Physical Simulation
**Purpose**: Modeling robot physics and testing PID controller.

**Components**:
- `RobotSimulator` - robot physical model class
  - Parameters: mass, friction, inertia
  - State: position, velocity, target position
  - Method `step()`: one simulation step using F=ma law
  
- `test_pid()` - PID controller testing function
  - Input: robot, PID parameters (Kp, Ki, Kd)
  - Output: performance metrics
    - `settling_time`: settling time (within 2% of target for 0.5 sec)
    - `overshoot`: maximum overshoot
    - `ss_error`: steady-state error
    - `score`: overall performance score (lower = better)
      - Formula: `settling_time + overshoot * 2 + ss_error * 5`

**Physical Model**:
- Friction force: `-friction * velocity`
- Net force: `control_force + friction_force`
- Acceleration: `a = F/m` (Newton's second law)
- Integration: Euler method with dt=0.01

### 2. `generate_data.py` - Dataset Generation
**Purpose**: Creating training dataset through simulation.

**Process**:
1. Generates 10,000 random experiments
2. For each experiment:
   - Random robot parameters: mass ∈ [0.5, 5.0], friction ∈ [0.1, 2.0], inertia ∈ [0.05, 0.5]
   - Random PID parameters: Kp ∈ [0.1, 20], Ki ∈ [0, 10], Kd ∈ [0, 5]
   - Runs simulation and collects metrics
3. Saves results to `pid_dataset.csv`

**Output**:
- CSV file with columns: mass, friction, inertia, Kp, Ki, Kd, settling_time, overshoot, ss_error, score

### 3. `data_preparation.py` - Common Data Preparation Module
**Purpose**: Centralized logic for data preparation, eliminating code duplication (DRY principle).

**Components**:
- `load_dataset()`: load dataset from CSV
- `save_training_data()`: save prepared data
- `print_statistics()`: print data statistics
- `strategy_best_per_robot()`: strategy 1 - best PID for each robot
- `strategy_top_percentile()`: strategy 2 - best results by percentile
- `prepare_features_labels()`: extract features and labels

**Principle**: Single point for common logic, strategies extracted into separate functions.

### 4. `prepare_training_data.py` - Data Preparation (Strategy 1)
**Purpose**: Select best PID parameters for each unique robot.

**Strategy**:
1. Uses `strategy_best_per_robot()` from `data_preparation.py`
2. Groups data by robot parameters (with rounding for grouping)
3. For each group, finds PID with minimum score
4. Creates pairs (robot parameters → optimal PID parameters)

**Output**:
- `X_train.npy`: robot parameters (mass, friction, inertia)
- `y_train.npy`: optimal PID parameters (Kp, Ki, Kd)

### 5. `prepare_training_data_v2.py` - Data Preparation (Strategy 2)
**Purpose**: Alternative strategy - select best results by score.

**Strategy**:
1. Uses `strategy_top_percentile()` from `data_preparation.py`
2. Selects top 30% results (by score quantile)
3. Uses all these pairs for training

**Difference from Strategy 1**: Does not group by robots, but takes simply best results.

### 6. `train_model.py` - Model Training
**Purpose**: Train neural network to predict PID parameters.

**Model Architecture**:
- Type: MLPRegressor (multi-layer perceptron)
- Architecture: 3 → 128 → 64 → 32 → 3
- Activation: ReLU
- Optimizer: Adam
- Regularization: Early stopping with validation_fraction=0.1

**Process**:
1. Load data (X_train.npy, y_train.npy)
2. Split train/test (80/20)
3. Normalize data (StandardScaler for X and y)
4. Train model
5. Evaluate quality (R², MSE for each parameter)
6. Save model and scalers

**Output Files**:
- `pid_model.pkl`: trained model
- `scaler_X.pkl`: input data scaler
- `scaler_y.pkl`: output data scaler

### 7. `predict_pid.py` - PID Parameter Prediction
**Purpose**: Use trained model to predict optimal PID parameters.

**Functions**:
- `predict_pid(mass, friction, inertia)`: main prediction function
  - Loads model and scalers
  - Normalizes input data
  - Makes prediction
  - Denormalizes output data
  - Returns dictionary with Kp, Ki, Kd

**Modes**:
- Interactive: prompts user for parameters
- Command line: accepts parameters as arguments

**Input**: robot parameters (mass, friction, inertia)  
**Output**: predicted PID parameters (Kp, Ki, Kd)

### 8. `test_model.py` - Model Testing
**Purpose**: Test trained model on new robots and compare with baseline manual tuning.

**Functions**:
- `load_model()`: load model and scalers
- `predict_pid()`: predict PID parameters
- `main()`: main testing loop

**Process**:
1. Tests on 3 robot types (light, medium, heavy)
2. Compares ML predictions with baseline manual tuning
3. Calculates performance improvement
4. Creates comparison plots

**Output Files**:
- `results_comparison.png`: ML vs Manual comparison plots for each robot type

### 9. `experiments.py` - Experiments for Research Paper
**Purpose**: Conduct experiments to validate method and prepare data for paper.

**Experiments**:
1. **Speed comparison**: ML prediction vs manual tuning (50 attempts)
2. **Generalization**: Testing on different robot types (light, medium, heavy)
3. **Noise robustness**: Performance at various sensor noise levels
4. **Accuracy across parameter space**: Testing on 100 random robots

**Output Files**:
- `noise_robustness.png`: noise robustness plot
- `improvement_distribution.png`: performance improvement distribution
- `experiment_results.npy`: results for statistical analysis

### 10. `statistical_analysis.py` - Statistical Analysis
**Purpose**: Statistical analysis of experiment results for research paper.

**Analysis Methods**:
- **Paired t-test**: compare ML and manual tuning
- **Wilcoxon test**: non-parametric alternative for robustness check
- **Cohen's d**: effect size
- **Descriptive statistics**: means, medians, standard deviations

**Output Files**:
- `statistical_results.json`: summary of statistical results

## Data Flows

### Data Generation
```
generate_data.py → pid_dataset.csv
```

### Data Preparation
```
pid_dataset.csv → prepare_training_data.py → X_train.npy, y_train.npy
```

### Training
```
X_train.npy, y_train.npy → train_model.py → pid_model.pkl, scaler_X.pkl, scaler_y.pkl
```

### Usage
```
robot_params → predict_pid.py → predicted_PID_params
```

Details:
```
robot_params → scaler_X → model → scaler_y → predicted_PID_params
```

### Testing and Experiments
```
pid_model.pkl → test_model.py → results_comparison.png
pid_model.pkl → experiments.py → experiment_results.npy
experiment_results.npy → statistical_analysis.py → statistical_results.json
```

## Data Schemas

### Input Data (X)
- `mass`: robot mass [0.5, 5.0]
- `friction`: friction coefficient [0.1, 2.0]
- `inertia`: moment of inertia [0.05, 0.5]

### Output Data (y)
- `Kp`: proportional coefficient [0.1, 20]
- `Ki`: integral coefficient [0, 10]
- `Kd`: derivative coefficient [0, 5]

### Performance Metrics
- `settling_time`: settling time (seconds)
- `overshoot`: maximum overshoot
- `ss_error`: steady-state error
- `score`: overall score (lower = better)

## Dependencies

- `numpy`: numerical computations
- `pandas`: data manipulation
- `matplotlib`: visualization
- `tqdm`: progress bar
- `scikit-learn`: machine learning
- `joblib`: model saving
- `scipy`: statistical analysis

## Non-Functional Requirements

- **Performance**: Dataset generation takes 2-4 hours (10,000 experiments)
- **Accuracy**: Model evaluated by R² and MSE for each PID parameter
- **Scalability**: Architecture allows easy increase of dataset size

## Architectural Decisions

1. **Separation of simulation and training**: Physical model separated from ML components
2. **Two data preparation strategies**: Allows experimenting with different approaches
3. **Centralization of data preparation logic**: `data_preparation.py` module eliminates duplication (DRY)
4. **Data normalization**: StandardScaler for training stability
5. **Early stopping**: Prevents overfitting
6. **Modularity**: Each component has clear responsibility (SOLID)

## Architecture Changelog

### 2025-01-XX (Experiments and Analysis)
- **Added experiment modules**: `test_model.py`, `experiments.py`, `statistical_analysis.py`
- **Implemented 4 experiments**: speed comparison, generalization, noise robustness, accuracy
- **Added statistical analysis**: paired t-test, Wilcoxon test, Cohen's d
- **Reason**: Prepare data for research paper, validate method
- **Impact**: Full cycle from training to statistical validation ready for publication

### 2025-01-XX (Refactoring)
- **Created `data_preparation.py` module**: Centralized data preparation logic
- **Refactored data preparation scripts**: Eliminated code duplication between strategies
- **Added `predict_pid.py` module**: Tool for using trained model
- **Reason**: Follow DRY and SOLID principles, improve code maintainability
- **Impact**: Simplified addition of new data preparation strategies, single entry point for predictions

### 2025-01-XX (Base Version)
- **Created base architecture**: Modules for simulation, data generation, data preparation, and training
- **Added two data preparation strategies**: Grouping by robots vs selecting best results
- **Reason**: Research different approaches to training data preparation
- **Impact**: Allows comparing effectiveness of different strategies
