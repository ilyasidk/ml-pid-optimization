# Reproducibility

This document describes how to reproduce all research results.

## Quick Reproduction

### Linux/macOS:
```bash
bash scripts/reproduce_results.sh
```

### Windows:
```cmd
scripts\reproduce_results.bat
```

## Step-by-Step Reproduction

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

Or use the script:
```bash
bash scripts/install_dependencies.sh
```

### 2. Generate Dataset (1-2 hours)

```bash
python src/generate_data_optimized.py
```

**Note:** Generates 1,000 robot configurations using Nelder-Mead optimization. Each robot takes 2-5 seconds to optimize.

### 3. Prepare Training Data

```bash
python src/prepare_training_data.py
```

Creates `data/X_train.npy` and `data/y_train.npy`.

### 4. Train Model

```bash
python src/train_model.py
```

Creates:
- `models/pid_model.pkl` - trained model
- `models/scaler_X.pkl` - input data scaler
- `models/scaler_y.pkl` - output data scaler

### 5. Check Model

```bash
python src/check_model.py
```

Verifies that the model works correctly.

### 6. Run Experiments (5-10 minutes)

```bash
python src/experiments.py
```

Runs 4 experiments:
1. Speed comparison (ML vs Baseline, Cohen-Coon, CHR)
2. Generalization to different robot types
3. Noise robustness
4. Accuracy on 1,000 random robots

Creates:
- `results/noise_robustness.png`
- `results/improvement_distribution.png`
- `results/results_comparison.png`
- `results/experiment_results.npy`

### 7. Statistical Analysis

```bash
python src/statistical_analysis_improved.py
```

Performs comprehensive statistical tests and creates:
- `results/statistical_comparison_baseline.png`
- `results/statistical_comparison_cc.png`
- `results/statistical_comparison_chr.png`
- `results/statistical_results_improved.json`
- LaTeX tables for paper

## Expected Results

After completing all steps, you will get:

### Model Metrics:
- R² Score: ~0.0873 (overall)
- R² for Kp: ~0.4429
- R² for Ki: ~-0.1860
- R² for Kd: ~0.0050
- **Note:** Lower R² scores indicate room for improvement, but model provides substantial practical gains

### Experiment Results:
- **ML vs Adaptive Baseline:**
  - Mean improvement: ~78.1% (95% CI: [77.6%, 78.5%])
  - Success rate: 100% (1,000/1,000)
  - p-value: < 1e-10
  - Cohen's d: ~5.66 (very large effect)

- **ML vs Cohen-Coon:**
  - Mean improvement: ~90.4% (95% CI: [90.0%, 90.7%])
  - Success rate: 100% (1,000/1,000)
  - p-value: < 1e-10
  - Cohen's d: ~6.62 (very large effect)

- **ML vs CHR:**
  - Mean improvement: ~51.7% (95% CI: [50.9%, 52.5%])
  - Success rate: 100% (1,000/1,000)
  - p-value: < 1e-10
  - Cohen's d: ~2.20 (large effect)

### Result Files:
- `results/improvement_distribution.png` - improvement distribution
- `results/noise_robustness.png` - noise robustness
- `results/results_comparison.png` - method comparison (ML, Baseline, CC, CHR)
- `results/statistical_comparison_baseline.png` - comprehensive stats ML vs Baseline
- `results/statistical_comparison_cc.png` - comprehensive stats ML vs Cohen-Coon
- `results/statistical_comparison_chr.png` - comprehensive stats ML vs CHR
- `results/statistical_results_improved.json` - all statistical metrics

## Reproducibility

All results are reproducible thanks to:
- **Fixed random seeds:** `random_state=42` and `np.random.seed(42)`
- **Deterministic algorithms:** scikit-learn with fixed seeds
- **Complete code:** all scripts available in repository

## Verifying Reproducibility

To verify that results match:

1. Run full reproduction
2. Compare metrics with those in paper (paper.md)
3. Check that plots are similar to `results/*.png`

**Note:** Small differences (< 1%) are possible due to library version or environment differences, but main results should match.

## Troubleshooting

### Error: "Model not found"
Make sure you completed steps 2-4 (data preparation and training).

### Error: "Dataset not found"
Run `python src/generate_data_optimized.py` (will take 1-2 hours).

### Result Differences
- Check library versions: `pip list`
- Make sure you're using Python 3.7+
- Verify that random seeds are set correctly

## Execution Time

| Step | Time |
|------|------|
| Data generation | 1-2 hours (1,000 robots, Nelder-Mead) |
| Data preparation | < 1 minute |
| Model training | 1-5 minutes |
| Experiments | 5-10 minutes (1,000 test cases) |
| Statistics | 1-2 minutes |
| **Total** | **~2-3 hours** |

## Using Results

After reproduction, you can:

1. **Use the model:**
   ```bash
   python src/predict_pid.py 2.0 0.7 0.15
   ```
   Note: Parameters are `mass`, `damping_coeff` (N·s/m), `inertia` (kg·m²)

2. **View results:**
   - Open `results/*.png` for plots
   - Open `results/statistical_results_improved.json` for metrics

3. **Use in paper:**
   - All metrics described in `paper.md`
   - Plots ready for inclusion in paper
   - LaTeX tables generated by statistical analysis
